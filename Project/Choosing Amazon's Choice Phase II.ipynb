{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KontomarisWuPhaseII.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ4Xt1uf1LT7"
      },
      "source": [
        "# Final Project Phase 2 Summary\n",
        "This Jupyter Notebook (.ipynb) will serve as the skeleton file for your submission for Phase 2 of the Final Project. Answer all statements addressed below as specified in the instructions for the project, covering all necessary details. Please be clear and concise in your answers. Each response should be at most 3 sentences. Good luck! <br><br>\n",
        "\n",
        "Note: To edit a Markdown cell, double-click on its text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjB_SbWY1LUB"
      },
      "source": [
        "## Jupyter Notebook Quick Tips\n",
        "Here are some quick formatting tips to get you started with Jupyter Notebooks. This is by no means exhaustive, and there are plenty of articles to highlight other things that can be done. We recommend using HTML syntax for Markdown but there is also Markdown syntax that is more streamlined and might be preferable. \n",
        "<a href = \"https://towardsdatascience.com/markdown-cells-jupyter-notebook-d3bea8416671\">Here's an article</a> that goes into more detail. (Double-click on cell to see syntax)\n",
        "\n",
        "# Heading 1\n",
        "## Heading 2\n",
        "### Heading 3\n",
        "#### Heading 4\n",
        "<br>\n",
        "<b>BoldText</b> or <i>ItalicText</i>\n",
        "<br> <br>\n",
        "Math Formulas: $x^2 + y^2 = 1$\n",
        "<br> <br>\n",
        "Line Breaks are done using br enclosed in < >.\n",
        "<br><br>\n",
        "Hyperlinks are done with: <a> https://www.google.com </a> or \n",
        "<a href=\"http://www.google.com\">Google</a><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb9oVjpRDswQ"
      },
      "source": [
        "# Data Collection and Cleaning\n",
        "You are required to provide data collection and cleaning for the three (3) minimum datasets. Create a function for each of the following sections that reads or scrapes data from a file or website, manipulate and cleans the parsed data, and writes the cleaned data into a new file. \n",
        "\n",
        "Make sure your data cleaning and manipulation process is not too simple. Performing complex manipulation and using modules not taught in class shows effort, which will increase the chance of receiving full credit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dp7Pm-Suh3d"
      },
      "source": [
        "## Data Sources\n",
        "Include sources (as links) to your datasets. Add any additional data sources if needed. Clearly indicate if a data source is different from one submitted in your Phase I, as we will check that it satisfies the requirements.\n",
        "*   Downloaded Dataset Source: https://personalization.ccs.neu.edu/Projects/Amazon/ Web scraped/crawled product information from Amazon product listings from 2015. \n",
        "*   Web Collection #1 Source: https://ahrefs.com/blog/top-amazon-searches/ A list of the most popular search terms on Amazon. \n",
        "*   Web Collection #2 Source: https://www.rainforestapi.com/docs/product-data-api/results/search An api that provides information on Amazon search results for a given keyword. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mRjxZDbE1tj"
      },
      "source": [
        "## Downloaded Dataset Requirement\n",
        "\n",
        "Fill in the predefined functions with your data scraping/parsing code. You may modify/rename each function as you seem fit, but you must provide at least 3 separate functions that clean each of your required datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p5xxmqzFGrO",
        "outputId": "b304a8fb-228e-46d4-c26a-8960ed430257"
      },
      "source": [
        "#from google.colab import files\n",
        "from pprint import pprint\n",
        "def data_parser(filename):\n",
        "  # Goal: Output a CSV that only has rows of data from Amazon buybox winners\n",
        "  import csv\n",
        "  with open(filename) as infile:\n",
        "    productsList = infile.readlines()\n",
        "  \n",
        "  cleanedList = [[\"Product ID\", \"Timestamp\", \"SID Rating\", \"Price\", \"Seller Rating\", \"Seller % Score\", \"Number of Seller Ratings\", \"Shipping Price\", \"Page\", \"Seller Rank\", \"PID Rating\", \"PID Rating Count\", \"isFBA\", \"isPrime\", \"Buybox SID\", \"Buybox Price\"]]\n",
        "  # Get the first Product ID & Timestamp\n",
        "  productID = productsList[0].strip().split()[0]\n",
        "  timeStamp = productsList[0].strip().split()[1]\n",
        "\n",
        "  for line in productsList:\n",
        "    listing = line.strip().split()\n",
        "    if listing[0] == productID and listing[1] == timeStamp:\n",
        "      winner = listing[14]\n",
        "      if listing[2] == winner:  # Checks if buybox\n",
        "        if listing[7] != -1:\n",
        "          if winner == \"amazon\":\n",
        "            listing[2] = 1\n",
        "          cleanedList.append(listing)\n",
        "    else:\n",
        "      if (listing[0] != productID) and listing[3] != 0 and listing[4] != \"nan\":\n",
        "        productID = listing[0] # Updates to the next Product ID\n",
        "  \n",
        "  with open(\"cleanedData.csv\", \"w\", newline = \"\") as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "    writer.writerows(cleanedList)\n",
        "############ Function Call ############\n",
        "data_parser(\"crawl2 copy.txt\")\n",
        "with open(\"cleanedData.csv\", \"r\") as f:\n",
        "  data = f.readlines()\n",
        "  pprint(data[:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Product ID,Timestamp,SID Rating,Price,Seller Rating,Seller % Score,Number of '\n",
            " 'Seller Ratings,Shipping Price,Page,Seller Rank,PID Rating,PID Rating '\n",
            " 'Count,isFBA,isPrime,Buybox SID,Buybox Price\\n',\n",
            " '0975277324,1439301853,1,40.36,5,100,4194304,0,1,4,5,2321,yes,yes,amazon,40.36\\n',\n",
            " 'B00000J0RJ,1439301853,1,3.97,5,100,4194304,0,1,0,4.5,171,yes,yes,amazon,3.97\\n',\n",
            " 'B00000JBNX,1439301853,1,10.99,5,100,4194304,0,1,0,4.5,1502,yes,yes,amazon,10.99\\n',\n",
            " 'B00002ND64,1439301853,1,18.98,5,100,4194304,0,1,0,4,824,yes,yes,amazon,18.98\\n',\n",
            " 'B00004R9TL,1439301853,1,22.94,5,100,4194304,0,1,5,4.5,1276,yes,yes,amazon,22.94\\n',\n",
            " 'B00004RBDU,1439301853,1,4.96,5,100,4194304,0,1,0,4,821,yes,no,amazon,4.96\\n',\n",
            " 'B00004RIZ7,1439301853,1,2.80,5,100,4194304,0,2,9,4.0,1645,no,no,amazon,2.80\\n',\n",
            " 'B00004S7V8,1439301853,A1TRPR6W5RNSTV,7.99,5,99,186,0,1,4,5,2089,yes,yes,A1TRPR6W5RNSTV,7.99\\n',\n",
            " 'B00004SQLJ,1439301853,1,7.09,5,100,4194304,0,1,0,4.5,494,yes,yes,amazon,7.09\\n',\n",
            " 'B00004TZY8,1439301853,1,5.45,5,100,4194304,0,1,3,4.5,827,yes,no,amazon,5.45\\n',\n",
            " 'B00004U9JO,1439301853,1,80.70,5,100,4194304,0,1,0,4.5,1509,yes,yes,amazon,80.70\\n',\n",
            " 'B00004UBGZ,1439301853,1,2.47,5,100,4194304,0,1,0,4.5,95,yes,yes,amazon,2.47\\n',\n",
            " 'B00004YO15,1439301853,1,2.97,5,100,4194304,0,1,0,4.5,714,yes,yes,amazon,2.97\\n',\n",
            " 'B00004YTJE,1439301853,AIFMPOK7LENBI,4.93,5,99,231,0,2,3,4.5,69,yes,yes,AIFMPOK7LENBI,4.93\\n',\n",
            " 'B00004Z4A8,1439301853,1,3.26,5,100,4194304,0,1,0,4.5,267,yes,no,amazon,3.26\\n',\n",
            " 'B00004Z4CP,1439301853,1,3.41,5,100,4194304,0,1,0,4.5,478,yes,no,amazon,3.41\\n',\n",
            " 'B00004Z5SM,1439301853,1,7.96,5,100,4194304,0,1,0,5,708,yes,yes,amazon,7.96\\n',\n",
            " 'B000052XHI,1439301853,ASEVS99O6FS73,17.47,5,97,203142,0,1,1,4.5,654,no,no,ASEVS99O6FS73,17.47\\n',\n",
            " 'B00005BXKM,1439301853,1,16.79,5,100,4194304,0,1,2,4,1156,yes,yes,amazon,16.79\\n',\n",
            " 'B00005O6B7,1439301853,1,10.17,5,100,4194304,0,1,1,4.5,487,yes,yes,amazon,10.17\\n',\n",
            " 'B000067EH7,1439301853,1,17.87,5,100,4194304,0,1,0,4.5,1801,yes,yes,amazon,17.87\\n',\n",
            " 'B000067PCE,1439301853,1,2.96,5,100,4194304,0,1,0,4.5,293,no,no,amazon,2.96\\n',\n",
            " 'B000067PQ0,1439301853,1,8.25,5,100,4194304,0,1,1,4.5,390,yes,yes,amazon,8.25\\n',\n",
            " 'B000068O36,1439301853,1,6.00,5,100,4194304,0,1,0,4,349,yes,yes,amazon,6.00\\n',\n",
            " 'B000068O3C,1439301853,1,5.70,5,100,4194304,0,1,0,4.5,744,yes,yes,amazon,5.70\\n',\n",
            " 'B000068PBT,1439301853,1,21.88,5,100,4194304,0,1,0,4.5,3033,yes,yes,amazon,21.88\\n',\n",
            " 'B00006ANDK,1439301853,1,19.99,5,100,4194304,0,1,0,4.5,1049,yes,yes,amazon,19.99\\n',\n",
            " 'B00006I551,1439301853,A29RCYP0O2CCF3,11.02,5,100,921,0,1,4,4.5,416,yes,yes,A29RCYP0O2CCF3,11.02\\n',\n",
            " 'B00006IBYA,1439301853,1,2.99,5,100,4194304,0,1,0,5,342,yes,yes,amazon,2.99\\n',\n",
            " 'B00006IDV8,1439301853,1,3.47,5,100,4194304,0,1,0,4.5,212,yes,yes,amazon,3.47\\n',\n",
            " 'B00006IEE4,1439301853,1,3.68,5,100,4194304,0,1,0,4.5,373,yes,yes,amazon,3.68\\n',\n",
            " 'B00006IEEU,1439301853,1,18.35,5,100,4194304,0,1,0,4.5,494,yes,yes,amazon,18.35\\n',\n",
            " 'B00006IEJC,1439301853,1,3.78,5,100,4194304,0,1,0,4.5,203,yes,yes,amazon,3.78\\n',\n",
            " 'B00006IESK,1439301853,1,1.99,5,100,4194304,0,1,0,4.5,37,yes,yes,amazon,1.99\\n',\n",
            " 'B00006IFAV,1439301853,1,4.99,5,100,4194304,0,1,0,4.5,518,no,no,amazon,4.99\\n',\n",
            " 'B00006IFH0,1439301853,1,6.88,5,100,4194304,0,1,0,4.5,685,yes,yes,amazon,6.88\\n',\n",
            " 'B00006IFKU,1439301853,1,4.77,5,100,4194304,0,1,0,4.5,407,yes,yes,amazon,4.77\\n',\n",
            " 'B00006IUWA,1439301853,1,16.94,5,100,4194304,0,1,0,4.5,6353,yes,yes,amazon,16.94\\n',\n",
            " 'B00006JNN7,1439301853,1,6.59,5,100,4194304,0,1,0,4.5,762,yes,yes,amazon,6.59\\n',\n",
            " 'B00006WNMJ,1439301853,1,12.67,5,100,4194304,0,1,0,4.5,1232,yes,yes,amazon,12.67\\n',\n",
            " 'B00008Y0VN,1439301853,1,76.49,5,100,4194304,0,1,0,4,1622,yes,yes,amazon,76.49\\n',\n",
            " 'B000096QQ5,1439301853,1,4.99,5,100,4194304,0,1,0,4.5,384,yes,no,amazon,4.99\\n',\n",
            " 'B00009IMCK,1439301853,1,3.99,5,100,4194304,0,1,0,4,729,yes,no,amazon,3.99\\n',\n",
            " 'B00009PGNT,1439301853,1,35.29,5,100,4194304,0,1,0,4,365,yes,yes,amazon,35.29\\n',\n",
            " 'B0000AQOH2,1439301853,1,2.58,5,100,4194304,0,1,0,4.5,230,yes,yes,amazon,2.58\\n',\n",
            " 'B0000AXRH5,1439301853,A2607QEGM8G1T2,5.30,5,100,35022,0,1,7,4.5,396,yes,yes,A2607QEGM8G1T2,5.30\\n',\n",
            " 'B0000CBK1L,1439301853,1,181.00,5,100,4194304,0,1,0,4.5,1963,yes,yes,amazon,181.00\\n',\n",
            " 'B0000YNR4M,1439301853,A3H89ADJHTH9SN,6.87,5,96,173737,0,1,0,4,1363,no,no,A3H89ADJHTH9SN,6.87\\n',\n",
            " 'B0000YUXI0,1439301853,A2TL77I99D8G2Z,13.95,5,98,13994,0,1,1,4.5,3206,yes,yes,A2TL77I99D8G2Z,13.95\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794L4vGXFdYw"
      },
      "source": [
        "## Web Collection Requirement \\#1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXwpJObDFiWM",
        "outputId": "37846a5f-e820-4643-b628-7a9223e08e52"
      },
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "# Goal: Generate a list of most searched Amazon keyword's in 2021 through webscraping\n",
        "def web_parser1():\n",
        "  url = \"https://ahrefs.com/blog/top-amazon-searches/\"\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  \n",
        "  with open(\"keywords.txt\", \"w\") as newfile:\n",
        "    for tag in soup.find_all(\"td\", {\"class\":\"column-2\"}):\n",
        "      keyword = tag.text.strip() + \"\\n\"\n",
        "      newfile.write(keyword)\n",
        "\n",
        "############ Function Call ############\n",
        "web_parser1()\n",
        "with open(\"keywords.txt\", \"r\") as f:\n",
        "  data = f.read()\n",
        "  print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nintendo switch\n",
            "laptop\n",
            "airpods\n",
            "headphones\n",
            "wireless earbuds\n",
            "ipad\n",
            "game of thrones\n",
            "fire stick\n",
            "ssd\n",
            "fitbit\n",
            "kindle\n",
            "tv\n",
            "air fryer\n",
            "bluetooth headphones\n",
            "roku\n",
            "toilet paper\n",
            "external hard drive\n",
            "tablet\n",
            "instant pot\n",
            "micro sd card\n",
            "gaming chair\n",
            "apple watch\n",
            "monitor\n",
            "earbuds\n",
            "ps4\n",
            "alexa\n",
            "paper towels\n",
            "desk\n",
            "office chair\n",
            "ring doorbell\n",
            "chromebook\n",
            "weighted blanket\n",
            "water bottle\n",
            "gift cards for amazon\n",
            "backpack\n",
            "hdmi cable\n",
            "lego\n",
            "wireless mouse\n",
            "mouse pad\n",
            "iphone charger\n",
            "hydro flask\n",
            "bluetooth earbuds\n",
            "gift card\n",
            "echo dot\n",
            "gaming mouse\n",
            "switch\n",
            "printer\n",
            "nintendo switch games\n",
            "keyboard\n",
            "bluetooth speakers\n",
            "iphone\n",
            "coffee\n",
            "aa batteries\n",
            "ps4 controller\n",
            "wireless headphones\n",
            "mouse\n",
            "shower curtain\n",
            "the boys\n",
            "shoes\n",
            "amazon gift cards\n",
            "led strip lights\n",
            "smart watch\n",
            "harry potter\n",
            "cbd oil\n",
            "kindle fire\n",
            "pop socket\n",
            "sd card\n",
            "xbox one controller\n",
            "ring\n",
            "microwave\n",
            "usb c cable\n",
            "good omens\n",
            "doctor who\n",
            "mattress\n",
            "gaming laptop\n",
            "hbo\n",
            "vacuum cleaner\n",
            "prime video\n",
            "iphone xr cases\n",
            "protein powder\n",
            "computer desk\n",
            "socks\n",
            "avengers endgame\n",
            "echo\n",
            "shoe rack\n",
            "iphone 11 case\n",
            "tv stand\n",
            "yoga mat\n",
            "aaa batteries\n",
            "gaming headset\n",
            "computer monitor\n",
            "blender\n",
            "books\n",
            "gaming pc\n",
            "dash cam\n",
            "pokemon\n",
            "luggage\n",
            "usb hub\n",
            "camera\n",
            "projector\n",
            "iphone xr cases\n",
            "iphone 11 case\n",
            "toilet paper\n",
            "paper towels\n",
            "water bottle\n",
            "coffee\n",
            "aa batteries\n",
            "shower curtain\n",
            "nintendo switch\n",
            "laptop\n",
            "ssd\n",
            "ps4\n",
            "kindle\n",
            "airpods\n",
            "ipad\n",
            "tablet\n",
            "alexa\n",
            "headphones\n",
            "iphone\n",
            "game of thrones\n",
            "lego\n",
            "switch\n",
            "fitbit\n",
            "tv\n",
            "harry potter\n",
            "monitor\n",
            "xiaomi\n",
            "apple watch\n",
            "wireless earbuds\n",
            "iphone 7\n",
            "fire stick\n",
            "bluetooth headphones\n",
            "iphone x\n",
            "samsung\n",
            "iphone xr\n",
            "iphone 8\n",
            "micro sd card\n",
            "gaming chair\n",
            "echo dot\n",
            "air fryer\n",
            "mouse\n",
            "smartphone\n",
            "smart watch\n",
            "star wars\n",
            "ps4 controller\n",
            "external hard drive\n",
            "water bottle\n",
            "instant pot\n",
            "roku\n",
            "keyboard\n",
            "chromebook\n",
            "pokemon\n",
            "huawei\n",
            "echo\n",
            "gaming mouse\n",
            "iphone 11\n",
            "backpack\n",
            "earbuds\n",
            "shoes\n",
            "toilet paper\n",
            "gaming pc\n",
            "playstation 4\n",
            "smartwatch\n",
            "wireless mouse\n",
            "desk\n",
            "power bank\n",
            "office chair\n",
            "notebook\n",
            "xbox one\n",
            "printer\n",
            "earphones\n",
            "mouse pad\n",
            "gaming laptop\n",
            "hdmi cable\n",
            "wireless headphones\n",
            "chromecast\n",
            "amazon\n",
            "nintendo switch games\n",
            "the boys\n",
            "drone\n",
            "sd card\n",
            "gift card\n",
            "xbox one controller\n",
            "ps4 games\n",
            "books\n",
            "camera\n",
            "avengers endgame\n",
            "ring doorbell\n",
            "gopro\n",
            "redmi note 7\n",
            "ipad pro\n",
            "ps4 pro\n",
            "powerbank\n",
            "funko pop\n",
            "good omens\n",
            "laptops\n",
            "windows 10\n",
            "lego star wars\n",
            "weighted blanket\n",
            "rtx 2060\n",
            "microwave\n",
            "anker\n",
            "fire tv stick\n",
            "bluetooth earbuds\n",
            "paper towels\n",
            "samsung galaxy s10\n",
            "blender\n",
            "projector\n",
            "iphone\n",
            "iphone 7\n",
            "iphone x\n",
            "iphone xr\n",
            "iphone 8\n",
            "iphone 11\n",
            "redmi note 7\n",
            "samsung galaxy s10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDD6sMsCXRxc"
      },
      "source": [
        "## Web Collection Requirement \\#2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAkUOqMgXQJG",
        "outputId": "55597348-32ef-4522-ed7d-d587092097c7"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "# Goal: Find Amazon's Choice and/or Bestseller for each of the most popular search keywords in 2021\n",
        "def web_parser2(filename):\n",
        "  # Read file from html to create a list of URL's\n",
        "  with open(filename) as infile:\n",
        "    keywordsList = infile.readlines()\n",
        "  urlList = []\n",
        "  for keyword in keywordsList:\n",
        "    urlList.append(get_url(keyword.strip()))\n",
        "  \n",
        "  # Loop through each search in urlList to find Amazon's Choice and/or Bestseller\n",
        "  overall = [] # List of lists\n",
        "  keyNames = [\"position\", \"is_prime\", \"rating\", \"ratings_total\", \"sponsored\"]\n",
        "  for url in urlList:\n",
        "    response = requests.get(url)\n",
        "    aDict = response.json()\n",
        "    keyword = aDict[\"request_parameters\"][\"search_term\"]  \n",
        "    # Loop through each listing in search\n",
        "    for product in aDict[\"search_results\"]:\n",
        "      # Check if Amazon's Choice and/or Bestseller\n",
        "      if \"amazons_choice\" in product.keys() or \"bestseller\" in product.keys():\n",
        "        # Create temporary list to store information about each individual listing\n",
        "        data = [keyword]\n",
        "        for key in keyNames:\n",
        "          try:\n",
        "            data.append(product[key])\n",
        "          except:\n",
        "            data.append(None)\n",
        "      \n",
        "        # After this loop ran we have\n",
        "        # data = [keyword, position, is_prime, rating, ratings_total, sponsored]\n",
        "        # Do Amazon's Choice & Besteller manually\n",
        "        if \"amazons_choice\" in product.keys():\n",
        "          data.append(True)  # Bool\n",
        "        else:\n",
        "          data.append(False)\n",
        "        \n",
        "        if \"bestseller\" in product.keys():\n",
        "          data.append(True)\n",
        "        else:\n",
        "          data.append(True)\n",
        "        # Now we have\n",
        "        # data = [keyword, position, is_prime, rating, ratings_total, sponsored, amazon's choice, bestseller]\n",
        "        # Do price & shipping price manually \n",
        "        try:\n",
        "          data.append(product[\"price\"][\"value\"]) # float\n",
        "        except:\n",
        "          data.append(None)\n",
        "        try:\n",
        "          data.append(product[\"delivery\"][\"price\"][\"value\"])\n",
        "        except:\n",
        "          data.append(None)\n",
        "        # Now we have\n",
        "        #data = [keyword, position, is_prime, rating, ratings_total, sponsored, amazon's choice, bestseller, price, shippingPrice]\n",
        "        overall.append(data)\n",
        "  # Create the dataframe\n",
        "  headers = [\"Keyword\", \"Position\", \"isPrime\", \"Rating\", \"numRatings\", \"Sponsored\", \"isChoice\", \"isBestseller\", \"Price\", \"shippingPrice\"]\n",
        "  # Overall is a list of lists, where each list is a single item, and we captured the data in headers\n",
        "  final = pd.DataFrame(overall, columns = headers)\n",
        "  final.to_csv(\"cleanedAPI.csv\")\n",
        "  print(final)\n",
        "\n",
        "def get_url(keyword):\n",
        "    # Generates a url from a keyword\n",
        "    apikey = \"889DDD89EA004AD2A158B1DB49686D37\" #Chris gatech\n",
        "    \n",
        "    #UsedUPapikey = \"0324BC2246E8471DBEFFE5F37D39EDCF\"\n",
        "    #chrisGmail = 73BEE2142C294F67A054D53420AEBBF5 \n",
        "    keyword = keyword.replace(\" \", \"+\")\n",
        "    url = f\"https://api.rainforestapi.com/request?api_key={apikey}&type=search&amazon_domain=amazon.com&search_term={keyword}\"\n",
        "    return url\n",
        "  \n",
        "############ Function Call ############\n",
        "web_parser2(\"keywords.txt\")\n",
        "print(\"Success!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Keyword  Position  isPrime  Rating  numRatings  Sponsored  \\\n",
            "0    nintendo switch         2    False     4.9       72419      False   \n",
            "1    nintendo switch        13     True     4.9      115755      False   \n",
            "2             laptop         3     True     4.6       26914      False   \n",
            "3            airpods         6     True     4.7        1768      False   \n",
            "4         headphones        10     True     4.7       37566      False   \n",
            "..               ...       ...      ...     ...         ...        ...   \n",
            "258          pokemon         6     True     4.5        7621      False   \n",
            "259          luggage         3     True     4.5       31876      False   \n",
            "260          luggage        18     True     4.6        8119      False   \n",
            "261          usb hub         3     True     4.7       62693      False   \n",
            "262          usb hub         6     True     4.6       63224      False   \n",
            "\n",
            "     isChoice  isBestseller   Price  shippingPrice  \n",
            "0       False          True  359.87            0.0  \n",
            "1       False          True   23.84            0.0  \n",
            "2        True          True  364.99            0.0  \n",
            "3        True          True   29.99            0.0  \n",
            "4       False          True   18.99            0.0  \n",
            "..        ...           ...     ...            ...  \n",
            "258     False          True    9.99            0.0  \n",
            "259      True          True   39.95            0.0  \n",
            "260     False          True   65.99            0.0  \n",
            "261      True          True   14.99            0.0  \n",
            "262     False          True    7.99            0.0  \n",
            "\n",
            "[263 rows x 10 columns]\n",
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezovwa1tp0we"
      },
      "source": [
        "## Additional Dataset Parsing/Cleaning Functions\n",
        "\n",
        "Write any supplemental (optional) functions here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4-s72RNuKLR"
      },
      "source": [
        "def extra_source1():\n",
        "    pass\n",
        "#helper functions are defined after their respective methods\n",
        "    \n",
        "############ Function Call ############\n",
        "extra_source1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB3qXt_XuY7b"
      },
      "source": [
        "# Define further extra source functions as necessary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uttEYrm9US5s"
      },
      "source": [
        "#Inconsistencies\n",
        "For each inconsistency (NaN, null, duplicate values, empty strings, etc.) you discover in your datasets, write at least 2 sentences stating the significance, how you identified it, and how you handled it.\n",
        "\n",
        "1. For the static data file, the shipping price can be 0, but not negative. \n",
        "However, the shipping price is displayed as -1 to indicate errors in the data (due to an error in downloading the page, scraping the data or because the price will only be displayed after adding the item to the cart). Since the shipping price is the 8th column of the file, we handled this error by only including rows where the 7th index is not equal to -1.\n",
        "\n",
        "2. For the static data file, the item cannot be free. For samples where the item price was found in error however, the price shows as \"0\". Since the item price is the 4th column of the file, we handled this error by only including rows where the 3rd index is not equal to 0.\n",
        "\n",
        "3. For the static data file, star ratings that were unavailanle were saved as \"nan\". Since the star rating is the 5th column of the file, we handled this error by only including rows where the 4th index is not \"nan\".\n",
        "\n",
        "4. For the Rainforest API, some items in the search results did not have a product or shipping price. We identified this error using a try and except block, and handled it by storing the value as None if it didn't exist. In cases where there were no product or shipping price, we still wanted to include the item because it's other information (such as isPrime, star ratings, etc) is relevant to our analysis.\n",
        "\n",
        "5. (if applicable)\n"
      ]
    }
  ]
}